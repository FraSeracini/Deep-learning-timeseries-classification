{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pirate Pain Prediction: Multi-Model Sequence Classification\n",
    "\n",
    "This notebook implements various deep learning models for predicting pirate pain levels from sequential motion data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 5555656\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Directory Structure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment timestamp: 20251117-181923\n"
     ]
    }
   ],
   "source": [
    "# Create necessary directories\n",
    "DATA_DIR = \"dataset\"\n",
    "PRED_DIR = \"prediction\"\n",
    "MODELS_DIR = \"models\"\n",
    "BEST_PARAM_DIR = \"best_param\"\n",
    "\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(BEST_PARAM_DIR, exist_ok=True)\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "CHECKPOINT_DIR = os.path.join(MODELS_DIR, timestamp, \"checkpoints\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f\"Experiment timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: Ensemble\n",
      "Batch size: 64\n",
      "Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Model and training configuration\n",
    "MODEL_TYPE = \"Ensemble\"  # Options: LSTM / GRU / Transformer / CNN1D / MLP / Ensemble / GNN\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 75\n",
    "LR = 1e-3\n",
    "VALID_SPLIT = 0.2\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "PREPROCESSING_VISUAL_CHECK = False\n",
    "\n",
    "# Preprocessing configurations\n",
    "PREPROCESSING_OPTS = {\n",
    "    \"gaussian\": \"none\",\n",
    "    \"exp\": \"min+asinh\", \n",
    "    \"pain\": \"none\"\n",
    "}\n",
    "\n",
    "SCALER_OPTS = {\n",
    "    \"gaussian\": \"standard\",\n",
    "    \"exp\": \"none\",\n",
    "    \"pain\": \"none\"\n",
    "}\n",
    "\n",
    "epsilon = 1e-6\n",
    "print(f\"Model type: {MODEL_TYPE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Initial Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (105760, 40)\n",
      "Test data shape: (211840, 40)\n",
      "Labels shape: (661, 2)\n",
      "Pain columns: 4\n",
      "Gaussian joints: 17\n",
      "Exponential joints: 13\n",
      "One-hot columns: 6\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "X_train = pd.read_csv(os.path.join(DATA_DIR, \"pirate_pain_train.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(DATA_DIR, \"pirate_pain_train_labels.csv\"))\n",
    "X_test = pd.read_csv(os.path.join(DATA_DIR, \"pirate_pain_test.csv\"))\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Labels shape: {y_train.shape}\")\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = ['n_legs', 'n_hands', 'n_eyes']\n",
    "X_train_enc = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "X_test_enc = pd.get_dummies(X_test, columns=categorical_cols)\n",
    "X_test_enc = X_test_enc.reindex(columns=X_train_enc.columns, fill_value=0)\n",
    "\n",
    "# Drop constant column\n",
    "for c in ['joint_30']:\n",
    "    if c in X_train_enc.columns:\n",
    "        X_train_enc.drop(columns=[c], inplace=True)\n",
    "        X_test_enc.drop(columns=[c], inplace=True)\n",
    "\n",
    "# Define feature groups based on distribution types\n",
    "pain_cols = [f\"pain_survey_{i}\" for i in range(1, 5)]\n",
    "gaussian_joints = [f\"joint_{i:02d}\" for i in range(0, 13)] + [f\"joint_{i}\" for i in range(26, 30)]\n",
    "exp_joints = [f\"joint_{i}\" for i in range(13, 26)]\n",
    "onehot_cols = [c for c in X_train_enc.columns if any(k in c for k in ['n_legs_', 'n_hands_', 'n_eyes_'])]\n",
    "\n",
    "print(f\"Pain columns: {len(pain_cols)}\")\n",
    "print(f\"Gaussian joints: {len(gaussian_joints)}\")\n",
    "print(f\"Exponential joints: {len(exp_joints)}\")\n",
    "print(f\"One-hot columns: {len(onehot_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(X_train, X_test, cols, option):\n",
    "    \"\"\"Apply preprocessing per feature group.\"\"\"\n",
    "    X_train_mod, X_test_mod = X_train.copy(), X_test.copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        if col not in X_train_mod.columns:\n",
    "            continue\n",
    "            \n",
    "        x_train, x_test = X_train_mod[col].values, X_test_mod[col].values\n",
    "        min_val = x_train.min()\n",
    "        x_train_shift = x_train - min_val + epsilon\n",
    "        x_test_shift = x_test - min_val + epsilon\n",
    "        \n",
    "        # Apply chosen preprocessing\n",
    "        if option == \"gaussian\":\n",
    "            X_train_mod[col] = gaussian_filter1d(x_train, sigma=1)\n",
    "            X_test_mod[col] = gaussian_filter1d(x_test, sigma=1)\n",
    "        elif option == \"min\":\n",
    "            X_train_mod[col] = x_train_shift\n",
    "            X_test_mod[col] = x_test_shift\n",
    "        elif option == \"min+log\":\n",
    "            X_train_mod[col] = np.log(x_train_shift)\n",
    "            X_test_mod[col] = np.log(x_test_shift)\n",
    "        elif option == \"min+asinh\":\n",
    "            X_train_mod[col] = np.arcsinh(x_train_shift)\n",
    "            X_test_mod[col] = np.arcsinh(x_test_shift)\n",
    "        elif option == \"boxcox\":\n",
    "            pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "            X_train_mod[col] = pt.fit_transform(x_train_shift.reshape(-1, 1)).ravel()\n",
    "            X_test_mod[col] = pt.transform(x_test_shift.reshape(-1, 1)).ravel()\n",
    "        elif option == \"none\":\n",
    "            pass  # leave as is\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown preprocessing option: {option}\")\n",
    "            \n",
    "    return X_train_mod, X_test_mod\n",
    "\n",
    "def apply_scaler(X_train, X_test, cols, option):\n",
    "    \"\"\"Apply scaling to feature groups.\"\"\"\n",
    "    if len(cols) == 0 or option == \"none\":\n",
    "        return X_train, X_test\n",
    "    \n",
    "    if option == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    elif option == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif option == \"robust\":\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scaler: {option}\")\n",
    "    \n",
    "    X_train[cols] = scaler.fit_transform(X_train[cols])\n",
    "    X_test[cols] = scaler.transform(X_test[cols])\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline completed\n",
      "Total features: 40\n",
      "Label mapping: {'high_pain': 0, 'low_pain': 1, 'no_pain': 2}\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing pipeline\n",
    "feature_cols = pain_cols + gaussian_joints + exp_joints + onehot_cols\n",
    "\n",
    "# Global preprocessing for CV\n",
    "X_train_full_for_cv = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "X_test_full_for_cv = pd.get_dummies(X_test, columns=categorical_cols)\n",
    "X_test_full_for_cv = X_test_full_for_cv.reindex(columns=X_train_full_for_cv.columns, fill_value=0)\n",
    "\n",
    "for c in ['joint_30']:\n",
    "    if c in X_train_full_for_cv.columns:\n",
    "        X_train_full_for_cv.drop(columns=[c], inplace=True)\n",
    "        X_test_full_for_cv.drop(columns=[c], inplace=True)\n",
    "\n",
    "# Global scaler\n",
    "global_scaler = StandardScaler()\n",
    "global_scaler.fit(X_train_full_for_cv[feature_cols])\n",
    "\n",
    "# Encode labels\n",
    "label_mapping = {label: idx for idx, label in enumerate(sorted(y_train['label'].unique()))}\n",
    "y_train['label_encoded'] = y_train['label'].map(label_mapping)\n",
    "\n",
    "print(\"Preprocessing pipeline completed\")\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"Label mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Cross-Validation Data Preparation\n",
    "# --------------------------\n",
    "\n",
    "def prepare_cv_data(train_ids, val_ids):\n",
    "    \"\"\"Prepare data for cross-validation without data leakage\"\"\"\n",
    "    tr_df = X_train[X_train['sample_index'].isin(train_ids)].copy()\n",
    "    va_df = X_train[X_train['sample_index'].isin(val_ids)].copy()\n",
    "    \n",
    "    # One-hot encoding \n",
    "    tr_enc = pd.get_dummies(tr_df, columns=categorical_cols)\n",
    "    va_enc = pd.get_dummies(va_df, columns=categorical_cols)\n",
    "    va_enc = va_enc.reindex(columns=tr_enc.columns, fill_value=0)\n",
    "\n",
    "    for c in ['joint_30']:\n",
    "        if c in tr_enc.columns:\n",
    "            tr_enc.drop(columns=[c], inplace=True)\n",
    "            va_enc.drop(columns=[c], inplace=True)\n",
    "\n",
    "    # Global preprocessing\n",
    "    tr_pp = tr_enc.copy()\n",
    "    va_pp = va_enc.copy()\n",
    "    \n",
    "    tr_pp[feature_cols] = global_scaler.transform(tr_enc[feature_cols])\n",
    "    va_pp[feature_cols] = global_scaler.transform(va_enc[feature_cols])\n",
    "    \n",
    "    return tr_pp, va_pp\n",
    "\n",
    "def make_fold_loaders(train_ids, val_ids):\n",
    "    \"\"\"Create data loaders for cross-validation folds\"\"\"\n",
    "    tr_pp, va_pp = prepare_cv_data(train_ids, val_ids)\n",
    "    \n",
    "    onehot_cols_fold = [c for c in tr_pp.columns if any(k in c for k in ['n_legs_', 'n_hands_', 'n_eyes_'])]\n",
    "    base_cols_fold = [c for c in (pain_cols + gaussian_joints + exp_joints) if c in tr_pp.columns]\n",
    "    feature_cols_fold = base_cols_fold + onehot_cols_fold\n",
    "    input_dim_fold = len(feature_cols_fold)\n",
    "    \n",
    "    ds_tr = PiratePainSeqDataset(tr_pp, y_train, feature_cols=feature_cols_fold)\n",
    "    ds_va = PiratePainSeqDataset(va_pp, y_train, feature_cols=feature_cols_fold)\n",
    "    \n",
    "    train_loader = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader, input_dim_fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Exploration and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final preprocessing summary:\n",
      "Pain cols: ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4']\n",
      "Gaussian joints: ['joint_00', 'joint_01', 'joint_02', 'joint_03', 'joint_04', 'joint_05', 'joint_06', 'joint_07', 'joint_08', 'joint_09', 'joint_10', 'joint_11', 'joint_12', 'joint_26', 'joint_27', 'joint_28', 'joint_29']\n",
      "Exponential joints: ['joint_13', 'joint_14', 'joint_15', 'joint_16', 'joint_17', 'joint_18', 'joint_19', 'joint_20', 'joint_21', 'joint_22', 'joint_23', 'joint_24', 'joint_25']\n",
      "One-hot cols: ['n_legs_one+peg_leg', 'n_legs_two', 'n_hands_one+hook_hand', 'n_hands_two', 'n_eyes_one+eye_patch', 'n_eyes_two']\n",
      "Preprocessing: {'gaussian': 'none', 'exp': 'min+asinh', 'pain': 'none'}\n",
      "Scalers: {'gaussian': 'standard', 'exp': 'none', 'pain': 'none'}\n",
      "Final feature columns (40): ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'joint_00', 'joint_01', 'joint_02', 'joint_03', 'joint_04', 'joint_05'] ...\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Data Exploration and Validation\n",
    "# --------------------------\n",
    "\n",
    "print(\"Final preprocessing summary:\")\n",
    "print(f\"Pain cols: {pain_cols}\")\n",
    "print(f\"Gaussian joints: {gaussian_joints}\")\n",
    "print(f\"Exponential joints: {exp_joints}\")\n",
    "print(f\"One-hot cols: {onehot_cols}\")\n",
    "print(f\"Preprocessing: {PREPROCESSING_OPTS}\")\n",
    "print(f\"Scalers: {SCALER_OPTS}\")\n",
    "print(f\"Final feature columns ({len(feature_cols)}): {feature_cols[:10]} ...\")\n",
    "\n",
    "def analyze_features_for_group(df, feature_cols, group_ids, time_col='time', \n",
    "                              sample_idx_col='sample_index', save_plots=False, plot_dir=\"plots\"):\n",
    "    \"\"\"Analyze feature distributions and temporal patterns for specific sample groups\"\"\"\n",
    "    \n",
    "    if isinstance(group_ids, (int, str)):\n",
    "        group_ids = [group_ids]\n",
    "\n",
    "    df_group = df[df[sample_idx_col].isin(group_ids)]\n",
    "\n",
    "    if df_group.empty:\n",
    "        print(f\"No data found for groups {group_ids}\")\n",
    "        return {}\n",
    "\n",
    "    if save_plots and not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "\n",
    "    stats_summary = {}\n",
    "\n",
    "    for col in feature_cols:\n",
    "        print(f\"\\n--- Analysis for {col} (groups {group_ids}) ---\")\n",
    "\n",
    "        series = df_group[col]\n",
    "        is_bool = set(series.unique()).issubset({0,1})\n",
    "\n",
    "        stats = {}\n",
    "        if is_bool:\n",
    "            counts_0 = (series == 0).sum()\n",
    "            counts_1 = (series == 1).sum()\n",
    "            total = counts_0 + counts_1\n",
    "            prop_0 = counts_0 / total if total > 0 else np.nan\n",
    "            prop_1 = counts_1 / total if total > 0 else np.nan\n",
    "            stats = {\n",
    "                'counts_0': counts_0,\n",
    "                'counts_1': counts_1,\n",
    "                'prop_0': prop_0,\n",
    "                'prop_1': prop_1\n",
    "            }\n",
    "        else:\n",
    "            stats = {\n",
    "                'min': series.min(),\n",
    "                'max': series.max(),\n",
    "                'mean': series.mean(),\n",
    "                'median': series.median(),\n",
    "                'std': series.std(),\n",
    "                '25%': series.quantile(0.25),\n",
    "                '75%': series.quantile(0.75),\n",
    "            }\n",
    "\n",
    "        stats_summary[col] = stats\n",
    "        for k, v in stats.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "        # Temporal plot\n",
    "        plt.figure(figsize=(8,4))\n",
    "        for idx, df_sub in df_group.groupby(sample_idx_col):\n",
    "            plt.plot(df_sub[time_col], df_sub[col], label=f\"{sample_idx_col}={idx}\", alpha=0.8)\n",
    "        plt.title(f\"{col} over time for group(s) {group_ids}\")\n",
    "        plt.xlabel(time_col)\n",
    "        plt.ylabel(col)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        if save_plots:\n",
    "            plt.savefig(os.path.join(plot_dir, f\"{col}_groups_{'_'.join(map(str, group_ids))}.png\"))\n",
    "        plt.show()\n",
    "\n",
    "        # Distribution plot\n",
    "        plt.figure(figsize=(6,4))\n",
    "        if is_bool:\n",
    "            sns.countplot(x=col, data=df_group)\n",
    "        else:\n",
    "            sns.histplot(series, bins=30, kde=True)\n",
    "        plt.title(f\"Distribution of {col} (group {group_ids})\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        if save_plots:\n",
    "            plt.savefig(os.path.join(plot_dir, f\"{col}_dist_groups_{'_'.join(map(str, group_ids))}.png\"))\n",
    "        plt.show()\n",
    "\n",
    "    return stats_summary\n",
    "\n",
    "# Execute data exploration if enabled\n",
    "if PREPROCESSING_VISUAL_CHECK:\n",
    "    print(\"\\\\n--- Running Data Exploration ---\")\n",
    "    stats_summary = analyze_features_for_group(X_train_enc, feature_cols, group_ids=4)\n",
    "    \n",
    "    print(\"\\\\n--- Dataset Shapes ---\")\n",
    "    print(\"X_train_enc shape:\", X_train_enc.shape) \n",
    "    print(\"y_train label column:\")\n",
    "    print(y_train['label'].head())\n",
    "    print(\"y_train encoded labels:\")\n",
    "    print(y_train['label_encoded'].unique())\n",
    "\n",
    "    # Label distribution plots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    sns.countplot(x='label', data=y_train, ax=ax1)\n",
    "    ax1.set_title(\"Distribution of Original Labels\")\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    sns.countplot(x='label_encoded', data=y_train, ax=ax2)\n",
    "    ax2.set_title(\"Distribution of Encoded Labels\")\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Dataset and DataLoader Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PiratePainSeqDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for sequential pirate pain data.\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y=None, feature_cols=None):\n",
    "        self.X, self.y = [], []\n",
    "        self.sample_ids = []\n",
    "        \n",
    "        if feature_cols is None:\n",
    "            onehot_cols_fold = [c for c in X.columns if any(k in c for k in ['n_legs_', 'n_hands_', 'n_eyes_'])]\n",
    "            base_cols_fold = [c for c in (pain_cols + gaussian_joints + exp_joints) if c in X.columns]\n",
    "            feature_cols = base_cols_fold + onehot_cols_fold\n",
    "        \n",
    "        self.feature_cols = feature_cols\n",
    "        y_map = None\n",
    "        \n",
    "        if y is not None:\n",
    "            y_map = y.set_index('sample_index')['label'].map(label_mapping)\n",
    "        \n",
    "        for idx, df_sub in X.groupby('sample_index'):\n",
    "            seq = df_sub[self.feature_cols].values.astype(np.float32)\n",
    "            self.X.append(seq)\n",
    "            self.sample_ids.append(idx)\n",
    "            \n",
    "            if y_map is not None:\n",
    "                if idx not in y_map.index:\n",
    "                    raise ValueError(f\"sample_index {idx} not found in y_train\")\n",
    "                self.y.append(y_map.loc[idx])\n",
    "        \n",
    "        print(f\"Total sequences loaded: {len(self.X)}\")\n",
    "        \n",
    "        if y is not None:\n",
    "            self.y = np.array(self.y)\n",
    "            print(f\"Total labels loaded: {len(self.y)}\")\n",
    "        else:\n",
    "            self.y = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        if self.y is not None:\n",
    "            return x, torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for padding sequences.\"\"\"\n",
    "    x, y = zip(*batch) if isinstance(batch[0], tuple) else (batch, None)\n",
    "    x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
    "    \n",
    "    if y is not None:\n",
    "        y = torch.stack(y)\n",
    "        return x_padded, y\n",
    "    return x_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentivePooling1D(nn.Module):\n",
    "    \"\"\"Attention-based pooling for sequence models.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = self.attention(x)\n",
    "        weights = F.softmax(scores, dim=1)\n",
    "        x_pooled = (x * weights).sum(dim=1)\n",
    "        return x_pooled\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM model for sequence classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_size, num_layers, num_classes, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_size, num_layers=num_layers, \n",
    "            batch_first=True, dropout=dropout, bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    \"\"\"GRU model with attention pooling.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_size=512, num_layers=4, num_classes=10, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden_size, num_layers=num_layers, \n",
    "            batch_first=True, dropout=dropout, bidirectional=True\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size*2)\n",
    "        self.att_pool = AttentivePooling1D(hidden_size*2)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.layer_norm(out)\n",
    "        out = self.att_pool(out)\n",
    "        return self.fc(out)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Transformer model for sequence classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes, hidden_dim=192, nhead=4, num_layers=2, max_seq_len=500, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.pos_enc = nn.Parameter(torch.randn(1, max_seq_len, hidden_dim))\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=nhead, dropout=dropout, \n",
    "            batch_first=True, dim_feedforward=hidden_dim*4, activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.att_pool = AttentivePooling1D(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.input_fc(x)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pos_enc[:, :seq_len, :]\n",
    "        x = self.transformer(x, src_key_padding_mask=mask)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.att_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock1D(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for 1D CNNs.\"\"\"\n",
    "    \n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.mean(dim=2)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).unsqueeze(-1)\n",
    "        return x * y\n",
    "\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    \"\"\"Residual block for 1D CNNs.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.se = SEBlock1D(out_channels)\n",
    "        self.skip = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.skip(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    \"\"\"1D CNN model with residual blocks and SE attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes, conv_channels, kernel_sizes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = input_dim\n",
    "        \n",
    "        for out_channels, k in zip(conv_channels, kernel_sizes):\n",
    "            layers.append(ResidualBlock1D(in_channels, out_channels, k, dropout))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        layers.append(nn.AdaptiveMaxPool1d(1))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(conv_channels[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.conv(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron model.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_sizes, num_classes, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_dim = h\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_sizes[-1], num_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.mean(dim=1)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \"\"\"Graph Neural Network model for sequence data.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, num_layers=2, heads=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.heads = heads\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout, concat=True))\n",
    "        \n",
    "        for _ in range(num_layers-1):\n",
    "            self.convs.append(GATConv(hidden_dim*heads, hidden_dim, heads=heads, dropout=dropout, concat=True))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.att_pool = AttentivePooling1D(hidden_dim*heads)\n",
    "        self.fc = nn.Linear(hidden_dim*heads, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, feat_dim = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create temporal edges\n",
    "        edge_indices = []\n",
    "        for b in range(batch_size):\n",
    "            row = torch.arange(seq_len-1, device=device) + b*seq_len\n",
    "            col = torch.arange(1, seq_len, device=device) + b*seq_len\n",
    "            edge_index = torch.stack([torch.cat([row, col]), torch.cat([col, row])], dim=0)\n",
    "            edge_indices.append(edge_index)\n",
    "        \n",
    "        edge_index = torch.cat(edge_indices, dim=1)\n",
    "        x = x.reshape(batch_size*seq_len, feat_dim)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        x = self.att_pool(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\"Ensemble of multiple models with learnable weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes, device, model_configs=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        if model_configs is None:\n",
    "            model_configs = {\n",
    "                \"cnn\": {\"conv_channels\": [48, 96, 160], \"kernel_sizes\": [5, 3, 3], \"dropout\": 0.4},\n",
    "                \"gru\": {\"hidden_size\": 192, \"num_layers\": 3, \"dropout\": 0.4},\n",
    "                \"lstm\": {\"hidden_size\": 192, \"num_layers\": 3, \"dropout\": 0.4},\n",
    "                \"transformer\": {\"hidden_dim\": 96, \"nhead\": 2, \"num_layers\": 3, \"dropout\": 0.3},\n",
    "                \"mlp\": {\"hidden_sizes\": [384, 192, 128], \"dropout\": 0.4}\n",
    "            }\n",
    "        \n",
    "        # Initialize individual models\n",
    "        self.cnn = CNN1DModel(\n",
    "            input_dim=input_dim, num_classes=num_classes,\n",
    "            conv_channels=model_configs[\"cnn\"][\"conv_channels\"],\n",
    "            kernel_sizes=model_configs[\"cnn\"][\"kernel_sizes\"],\n",
    "            dropout=model_configs[\"cnn\"][\"dropout\"]\n",
    "        )\n",
    "        \n",
    "        self.gru = GRUModel(\n",
    "            input_dim=input_dim, hidden_size=model_configs[\"gru\"][\"hidden_size\"],\n",
    "            num_layers=model_configs[\"gru\"][\"num_layers\"], num_classes=num_classes,\n",
    "            dropout=model_configs[\"gru\"][\"dropout\"]\n",
    "        )\n",
    "        \n",
    "        self.lstm = LSTMModel(\n",
    "            input_dim=input_dim, hidden_size=model_configs[\"lstm\"][\"hidden_size\"],\n",
    "            num_layers=model_configs[\"lstm\"][\"num_layers\"], num_classes=num_classes,\n",
    "            dropout=model_configs[\"lstm\"][\"dropout\"]\n",
    "        )\n",
    "        \n",
    "        self.transformer = TransformerModel(\n",
    "            input_dim=input_dim, num_classes=num_classes,\n",
    "            hidden_dim=model_configs[\"transformer\"][\"hidden_dim\"],\n",
    "            nhead=model_configs[\"transformer\"][\"nhead\"],\n",
    "            num_layers=model_configs[\"transformer\"][\"num_layers\"],\n",
    "            max_seq_len=500, dropout=model_configs[\"transformer\"][\"dropout\"]\n",
    "        )\n",
    "        \n",
    "        self.mlp = MLPModel(\n",
    "            input_dim=input_dim, hidden_sizes=model_configs[\"mlp\"][\"hidden_sizes\"],\n",
    "            num_classes=num_classes, dropout=model_configs[\"mlp\"][\"dropout\"]\n",
    "        )\n",
    "        \n",
    "        # Learnable ensemble weights\n",
    "        self.model_weights = nn.Parameter(torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0]), requires_grad=True)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_cnn = self.cnn(x)\n",
    "        out_gru = self.gru(x)\n",
    "        out_lstm = self.lstm(x)\n",
    "        out_trans = self.transformer(x)\n",
    "        out_mlp = self.mlp(x)\n",
    "        \n",
    "        logits = torch.stack([out_cnn, out_gru, out_lstm, out_trans, out_mlp], dim=1)\n",
    "        weights = self.softmax(self.model_weights).unsqueeze(0).unsqueeze(-1)\n",
    "        weighted_logits = (logits * weights).sum(dim=1)\n",
    "        \n",
    "        return weighted_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Configuration Management \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Configuration Management\n",
    "# --------------------------\n",
    "\n",
    "def load_best_configs_for_ensemble():\n",
    "    \"\"\"Load best configurations for each model type to build ensemble.\"\"\"\n",
    "    name_map = {\n",
    "        \"CNN1D\": \"cnn\",\n",
    "        \"GRU\": \"gru\", \n",
    "        \"LSTM\": \"lstm\",\n",
    "        \"Transformer\": \"transformer\",\n",
    "        \"MLP\": \"mlp\",\n",
    "    }\n",
    "    \n",
    "    default_configs = {\n",
    "        \"cnn\": {\"conv_channels\": [48, 96, 160], \"kernel_sizes\": [5, 3, 3], \"dropout\": 0.4},\n",
    "        \"gru\": {\"hidden_size\": 192, \"num_layers\": 3, \"dropout\": 0.4},\n",
    "        \"lstm\": {\"hidden_size\": 192, \"num_layers\": 3, \"dropout\": 0.4},\n",
    "        \"transformer\": {\"hidden_dim\": 96, \"nhead\": 2, \"num_layers\": 3, \"dropout\": 0.3},\n",
    "        \"mlp\": {\"hidden_sizes\": [384, 192, 128], \"dropout\": 0.4},\n",
    "    }\n",
    "\n",
    "    model_configs = {}\n",
    "    \n",
    "    for mt, key in name_map.items():\n",
    "        cfg_path = os.path.join(BEST_PARAM_DIR, f\"best_cfg_{mt}.json\")\n",
    "        if os.path.exists(cfg_path):\n",
    "            with open(cfg_path, \"r\") as f:\n",
    "                loaded = json.load(f)\n",
    "            \n",
    "            # Load configuration based on model type\n",
    "            if key == \"cnn\":\n",
    "                model_configs[key] = {\n",
    "                    \"conv_channels\": loaded.get(\"conv_channels\", default_configs[key][\"conv_channels\"]),\n",
    "                    \"kernel_sizes\": loaded.get(\"kernel_sizes\", default_configs[key][\"kernel_sizes\"]),\n",
    "                    \"dropout\": loaded.get(\"dropout\", default_configs[key][\"dropout\"]),\n",
    "                }\n",
    "            elif key in (\"gru\", \"lstm\"):\n",
    "                model_configs[key] = {\n",
    "                    \"hidden_size\": loaded.get(\"hidden_size\", default_configs[key][\"hidden_size\"]),\n",
    "                    \"num_layers\": loaded.get(\"num_layers\", default_configs[key][\"num_layers\"]),\n",
    "                    \"dropout\": loaded.get(\"dropout\", default_configs[key][\"dropout\"]),\n",
    "                }\n",
    "            elif key == \"transformer\":\n",
    "                model_configs[key] = {\n",
    "                    \"hidden_dim\": loaded.get(\"hidden_dim\", default_configs[key][\"hidden_dim\"]),\n",
    "                    \"nhead\": loaded.get(\"nhead\", default_configs[key][\"nhead\"]),\n",
    "                    \"num_layers\": loaded.get(\"num_layers\", default_configs[key][\"num_layers\"]),\n",
    "                    \"dropout\": loaded.get(\"dropout\", default_configs[key][\"dropout\"]),\n",
    "                }\n",
    "            elif key == \"mlp\":\n",
    "                model_configs[key] = {\n",
    "                    \"hidden_sizes\": loaded.get(\"hidden_sizes\", default_configs[key][\"hidden_sizes\"]),\n",
    "                    \"dropout\": loaded.get(\"dropout\", default_configs[key][\"dropout\"]),\n",
    "                }\n",
    "            print(f\"Loaded best config for {mt} -> key '{key}'\")\n",
    "        else:\n",
    "            print(f\"Warning: No best config found for {mt}, using defaults\")\n",
    "            model_configs[key] = default_configs[key]\n",
    "\n",
    "    return model_configs\n",
    "\n",
    "def save_best_config(model_type, best_cfg):\n",
    "    \"\"\"Save the best configuration for a model type to JSON file.\"\"\"\n",
    "    config_file = os.path.join(BEST_PARAM_DIR, f\"best_cfg_{model_type}.json\")\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(best_cfg, f, indent=2)\n",
    "    print(f\"Best configuration for {model_type} saved at: {config_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_by_type(cfg=None, input_dim=None, num_classes_arg=None):\n",
    "    \"\"\"Factory function to build models based on configuration.\"\"\"\n",
    "    if cfg is None:\n",
    "        cfg = {}\n",
    "    \n",
    "    mtype = cfg.get(\"type\", MODEL_TYPE)\n",
    "    \n",
    "    if num_classes_arg is None:\n",
    "        num_classes_arg = len(label_mapping)\n",
    "    \n",
    "    if input_dim is None:\n",
    "        raise ValueError(\"build_model_by_type requires input_dim to construct correct layers.\")\n",
    "    \n",
    "    # Build specific model type\n",
    "    if mtype == \"LSTM\":\n",
    "        return LSTMModel(input_dim, cfg.get(\"hidden_size\",192), cfg.get(\"num_layers\",3), \n",
    "                       num_classes_arg, cfg.get(\"dropout\",0.4)).to(device)\n",
    "    \n",
    "    elif mtype == \"GRU\":\n",
    "        return GRUModel(input_dim, cfg.get(\"hidden_size\",192), cfg.get(\"num_layers\",3), \n",
    "                      num_classes_arg, cfg.get(\"dropout\",0.4)).to(device)\n",
    "    \n",
    "    elif mtype == \"Transformer\":\n",
    "        return TransformerModel(input_dim, num_classes_arg, cfg.get(\"hidden_dim\",96), \n",
    "                              cfg.get(\"nhead\",2), cfg.get(\"num_layers\",3), 500, \n",
    "                              cfg.get(\"dropout\",0.3)).to(device)\n",
    "    \n",
    "    elif mtype == \"CNN1D\":\n",
    "        return CNN1DModel(input_dim, num_classes_arg, cfg.get(\"conv_channels\",[48,96,160]), \n",
    "                        cfg.get(\"kernel_sizes\",[5,3,3]), cfg.get(\"dropout\",0.4)).to(device)\n",
    "    \n",
    "    elif mtype == \"MLP\":\n",
    "        return MLPModel(input_dim, cfg.get(\"hidden_sizes\",[384,192,128]), \n",
    "                      num_classes_arg, cfg.get(\"dropout\",0.4)).to(device)\n",
    "    \n",
    "    elif mtype == \"GNN\":\n",
    "        return GNNModel(input_dim=input_dim, hidden_dim=cfg.get(\"hidden_dim\", 128), \n",
    "                      num_classes=num_classes_arg, num_layers=cfg.get(\"num_layers\", 2), \n",
    "                      heads=cfg.get(\"heads\", 4), dropout=cfg.get(\"dropout\", 0.3)).to(device)\n",
    "    \n",
    "    elif mtype == \"Ensemble\":\n",
    "        model_configs = load_best_configs_for_ensemble()\n",
    "        return EnsembleModel(input_dim, num_classes_arg, device, model_configs).to(device)\n",
    "    \n",
    "    raise ValueError(\"MODEL_TYPE not supported\")\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    \"\"\"Train model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_f1(model, loader, criterion):\n",
    "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
    "    model.eval()\n",
    "    vloss = 0.0\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            vloss += criterion(logits, yb).item()\n",
    "            \n",
    "            predictions.append(logits.argmax(1).cpu().numpy())\n",
    "            true_labels.append(yb.cpu().numpy())\n",
    "    \n",
    "    vloss /= len(loader)\n",
    "    y_pred = np.concatenate(predictions)\n",
    "    y_true = np.concatenate(true_labels)\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    return vloss, f1, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Cross-Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter tuning for MODEL_TYPE = Ensemble\n",
      "Found 3 configurations.\n",
      "\n",
      "--- Testing configuration: {'type': 'Ensemble', 'lr': 0.001} ---\n",
      "Total sequences loaded: 594\n",
      "Total labels loaded: 594\n",
      "Total sequences loaded: 67\n",
      "Total labels loaded: 67\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francesco\\anaconda3\\envs\\pirate-pain\\lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10: F1=0.9492 | Acc=0.9851 | Prec=0.9937 | Rec=0.9167\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 2/10: F1=0.6675 | Acc=0.8333 | Prec=0.6875 | Rec=0.6511\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 3/10: F1=0.7503 | Acc=0.8788 | Prec=0.7511 | Rec=0.7639\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 4/10: F1=0.8659 | Acc=0.9394 | Prec=0.9474 | Rec=0.8238\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 5/10: F1=0.6030 | Acc=0.8333 | Prec=0.6813 | Rec=0.5764\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 6/10: F1=0.4339 | Acc=0.8333 | Prec=0.4661 | Rec=0.4224\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 7/10: F1=0.8705 | Acc=0.9394 | Prec=0.8978 | Rec=0.8495\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 8/10: F1=0.8238 | Acc=0.9394 | Prec=0.8363 | Rec=0.8187\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 9/10: F1=0.6665 | Acc=0.8636 | Prec=0.6649 | Rec=0.6733\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 10/10: F1=0.6386 | Acc=0.8636 | Prec=0.6925 | Rec=0.6047\n",
      "Configuration {'type': 'Ensemble', 'lr': 0.001} => F1: 0.7269  0.1468 | Acc: 0.8909  0.0524 | Prec: 0.7619  0.1504 | Rec: 0.7100  0.1436\n",
      "\n",
      "--- Testing configuration: {'type': 'Ensemble', 'lr': 0.0005} ---\n",
      "Total sequences loaded: 594\n",
      "Total labels loaded: 594\n",
      "Total sequences loaded: 67\n",
      "Total labels loaded: 67\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 1/10: F1=0.8792 | Acc=0.9552 | Prec=0.8601 | Rec=0.9038\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 2/10: F1=0.7224 | Acc=0.8939 | Prec=0.7787 | Rec=0.7044\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 3/10: F1=0.7438 | Acc=0.8788 | Prec=0.7679 | Rec=0.7486\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 4/10: F1=0.8081 | Acc=0.9242 | Prec=0.8478 | Rec=0.8027\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 5/10: F1=0.6956 | Acc=0.8636 | Prec=0.7253 | Rec=0.6716\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 6/10: F1=0.6068 | Acc=0.8788 | Prec=0.6433 | Rec=0.5843\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 7/10: F1=0.7856 | Acc=0.9091 | Prec=0.9286 | Rec=0.7121\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 8/10: F1=0.7907 | Acc=0.9242 | Prec=0.8067 | Rec=0.7770\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 9/10: F1=0.6055 | Acc=0.8636 | Prec=0.6157 | Rec=0.6010\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 10/10: F1=0.8579 | Acc=0.9394 | Prec=0.8791 | Rec=0.8408\n",
      "Configuration {'type': 'Ensemble', 'lr': 0.0005} => F1: 0.7495  0.0893 | Acc: 0.9031  0.0306 | Prec: 0.7853  0.0960 | Rec: 0.7347  0.0961\n",
      "\n",
      "--- Testing configuration: {'type': 'Ensemble', 'lr': 0.0001} ---\n",
      "Total sequences loaded: 594\n",
      "Total labels loaded: 594\n",
      "Total sequences loaded: 67\n",
      "Total labels loaded: 67\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 1/10: F1=0.5670 | Acc=0.8060 | Prec=0.6052 | Rec=0.5425\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 2/10: F1=0.6461 | Acc=0.8333 | Prec=0.7460 | Rec=0.5978\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 3/10: F1=0.6458 | Acc=0.8333 | Prec=0.7346 | Rec=0.6819\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 4/10: F1=0.8975 | Acc=0.9545 | Prec=0.9231 | Rec=0.8980\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 5/10: F1=0.2969 | Acc=0.8030 | Prec=0.2677 | Rec=0.3333\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 6/10: F1=0.4821 | Acc=0.8485 | Prec=0.5046 | Rec=0.4700\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 7/10: F1=0.6664 | Acc=0.8485 | Prec=0.6852 | Rec=0.6622\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 8/10: F1=0.7260 | Acc=0.9091 | Prec=0.8099 | Rec=0.6750\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 9/10: F1=0.6279 | Acc=0.8636 | Prec=0.6375 | Rec=0.6480\n",
      "Total sequences loaded: 595\n",
      "Total labels loaded: 595\n",
      "Total sequences loaded: 66\n",
      "Total labels loaded: 66\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Fold 10/10: F1=0.7923 | Acc=0.9091 | Prec=0.7967 | Rec=0.7927\n",
      "Configuration {'type': 'Ensemble', 'lr': 0.0001} => F1: 0.6348  0.1567 | Acc: 0.8609  0.0465 | Prec: 0.6710  0.1745 | Rec: 0.6302  0.1506\n",
      "\n",
      "============================================================\n",
      ">>> BEST CONFIGURATION FOUND:\n",
      "{'type': 'Ensemble', 'lr': 0.0005}\n",
      "\n",
      "Cross-Validation Performance (macro metrics):\n",
      "  F1 Score  : 0.7495  0.0893\n",
      "  Accuracy  : 0.9031  0.0306\n",
      "  Precision : 0.7853  0.0960\n",
      "  Recall    : 0.7347  0.0961\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare cross-validation\n",
    "seq_ids = np.array(sorted(X_train['sample_index'].unique()))\n",
    "y_seq = y_train.set_index('sample_index').loc[seq_ids, 'label'].map(label_mapping).values\n",
    "groups = seq_ids.copy()\n",
    "\n",
    "K = 10\n",
    "gkf = GroupKFold(n_splits=K)\n",
    "\n",
    "# ===== Hyperparameter Grids =====\n",
    "all_param_grid = [\n",
    "    # ---------- MLP ----------\n",
    "    {\"type\": \"MLP\", \"hidden_sizes\": [256,128],       \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"type\": \"MLP\", \"hidden_sizes\": [384,192,128],   \"dropout\": 0.4, \"lr\": 1e-3},\n",
    "    {\"type\": \"MLP\", \"hidden_sizes\": [512,256,128],   \"dropout\": 0.4, \"lr\": 1e-3},\n",
    "    {\"type\": \"MLP\", \"hidden_sizes\": [512,256,128,64],\"dropout\": 0.5, \"lr\": 1e-3},\n",
    "    {\"type\": \"MLP\", \"hidden_sizes\": [256,128],       \"dropout\": 0.3, \"lr\": 5e-4},\n",
    "\n",
    "    # ---------- GRU ----------\n",
    "    {\"type\": \"GRU\", \"hidden_size\": 128, \"num_layers\": 2, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"type\": \"GRU\", \"hidden_size\": 192, \"num_layers\": 3, \"dropout\": 0.4, \"lr\": 1e-3},\n",
    "    {\"type\": \"GRU\", \"hidden_size\": 256, \"num_layers\": 2, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"type\": \"GRU\", \"hidden_size\": 256, \"num_layers\": 3, \"dropout\": 0.5, \"lr\": 1e-3},\n",
    "    {\"type\": \"GRU\", \"hidden_size\": 320, \"num_layers\": 3, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "\n",
    "    # ---------- LSTM ----------\n",
    "    {\"type\": \"LSTM\", \"hidden_size\": 128, \"num_layers\": 2, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"type\": \"LSTM\", \"hidden_size\": 192, \"num_layers\": 3, \"dropout\": 0.4, \"lr\": 1e-3},\n",
    "    {\"type\": \"LSTM\", \"hidden_size\": 256, \"num_layers\": 2, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"type\": \"LSTM\", \"hidden_size\": 320, \"num_layers\": 3, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"type\": \"LSTM\", \"hidden_size\": 192, \"num_layers\": 4, \"dropout\": 0.5, \"lr\": 1e-3},\n",
    "\n",
    "    # ---------- CNN1D ----------\n",
    "    {\"type\": \"CNN1D\", \"conv_channels\": [32,64,128],     \"kernel_sizes\": [5,3,3], \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"type\": \"CNN1D\", \"conv_channels\": [48,96,160],     \"kernel_sizes\": [5,3,3], \"dropout\": 0.4, \"lr\": 1e-3},\n",
    "    {\"type\": \"CNN1D\", \"conv_channels\": [64,128,256],    \"kernel_sizes\": [5,3,3], \"dropout\": 0.5, \"lr\": 5e-4},\n",
    "    {\"type\": \"CNN1D\", \"conv_channels\": [64,128,256,512],\"kernel_sizes\": [7,5,3,3], \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "\n",
    "    # ---------- TRANSFORMER ----------\n",
    "    {\"type\": \"Transformer\", \"hidden_dim\": 96,  \"nhead\": 2, \"num_layers\": 3, \"dropout\": 0.3, \"lr\": 5e-4},\n",
    "    {\"type\": \"Transformer\", \"hidden_dim\": 128, \"nhead\": 4, \"num_layers\": 3, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"type\": \"Transformer\", \"hidden_dim\": 192, \"nhead\": 4, \"num_layers\": 4, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"type\": \"Transformer\", \"hidden_dim\": 256, \"nhead\": 8, \"num_layers\": 4, \"dropout\": 0.4, \"lr\": 3e-4},\n",
    "    {\"type\": \"Transformer\", \"hidden_dim\": 128, \"nhead\": 4, \"num_layers\": 2, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "\n",
    "    # ---------- GNN ----------\n",
    "    {\"type\": \"GNN\", \"hidden_dim\": 96,  \"num_layers\": 2, \"heads\": 4, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"type\": \"GNN\", \"hidden_dim\": 128, \"num_layers\": 2, \"heads\": 4, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"type\": \"GNN\", \"hidden_dim\": 128, \"num_layers\": 3, \"heads\": 4, \"dropout\": 0.3, \"lr\": 5e-4},\n",
    "    {\"type\": \"GNN\", \"hidden_dim\": 192, \"num_layers\": 3, \"heads\": 4, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"type\": \"GNN\", \"hidden_dim\": 192, \"num_layers\": 2, \"heads\": 8, \"dropout\": 0.3, \"lr\": 3e-4},\n",
    "\n",
    "    # ---------- ENSEMBLE ----------\n",
    "    {\"type\": \"Ensemble\", \"lr\": 1e-3},\n",
    "    {\"type\": \"Ensemble\", \"lr\": 5e-4},\n",
    "    {\"type\": \"Ensemble\", \"lr\": 1e-4},\n",
    "]\n",
    "\n",
    "# Filter grid for current model type\n",
    "param_grid = [cfg for cfg in all_param_grid if cfg[\"type\"] == MODEL_TYPE]\n",
    "\n",
    "print(f\"\\nHyperparameter tuning for MODEL_TYPE = {MODEL_TYPE}\")\n",
    "print(f\"Found {len(param_grid)} configurations.\")\n",
    "\n",
    "# Initialize best results tracking\n",
    "best_cfg, best_mean_f1 = None, -1.0\n",
    "best_std_f1 = None\n",
    "best_mean_acc = best_std_acc = None\n",
    "best_mean_prec = best_std_prec = None\n",
    "best_mean_rec = best_std_rec = None\n",
    "\n",
    "# Cross-validation loop\n",
    "for cfg in param_grid:\n",
    "    fold_f1_scores = []\n",
    "    fold_acc_scores = []\n",
    "    fold_prec_scores = []\n",
    "    fold_rec_scores = []\n",
    "\n",
    "    print(f\"\\n--- Testing configuration: {cfg} ---\")\n",
    "    \n",
    "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(seq_ids, y_seq, groups=groups)):\n",
    "        train_ids = seq_ids[tr_idx]\n",
    "        val_ids = seq_ids[va_idx]\n",
    "        \n",
    "        # Create data loaders for this fold\n",
    "        train_loader, val_loader, input_dim_fold = make_fold_loaders(train_ids, val_ids)\n",
    "\n",
    "        # Build model with current configuration\n",
    "        model = build_model_by_type(cfg, input_dim=input_dim_fold)\n",
    "        lr = cfg.get(\"lr\", LR if cfg[\"type\"] != \"Transformer\" else LR * 0.5)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.3,\n",
    "            patience=(3 if cfg[\"type\"] == \"Transformer\" else 5),\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "\n",
    "        # Training loop with early stopping\n",
    "        best_vloss, wait, best_state = float('inf'), 0, None\n",
    "        \n",
    "        for epoch in range(1, NUM_EPOCHS + 1):\n",
    "            _ = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "            vloss, vf1, vacc, vprec, vrec = eval_f1(model, val_loader, criterion)\n",
    "            scheduler.step(vloss)\n",
    "\n",
    "            if vloss < best_vloss - 1e-4:\n",
    "                best_vloss, wait = vloss, 0\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= EARLY_STOPPING_PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # Load best model and evaluate\n",
    "        model.load_state_dict(best_state)\n",
    "        _, vf1, vacc, vprec, vrec = eval_f1(model, val_loader, criterion)\n",
    "\n",
    "        fold_f1_scores.append(vf1)\n",
    "        fold_acc_scores.append(vacc)\n",
    "        fold_prec_scores.append(vprec)\n",
    "        fold_rec_scores.append(vrec)\n",
    "\n",
    "        print(f\"Fold {fold+1}/{K}: F1={vf1:.4f} | Acc={vacc:.4f} | Prec={vprec:.4f} | Rec={vrec:.4f}\")\n",
    "\n",
    "    # Calculate mean and std for this configuration\n",
    "    mean_f1 = float(np.mean(fold_f1_scores))\n",
    "    std_f1 = float(np.std(fold_f1_scores))\n",
    "    mean_acc = float(np.mean(fold_acc_scores))\n",
    "    std_acc = float(np.std(fold_acc_scores))\n",
    "    mean_prec = float(np.mean(fold_prec_scores))\n",
    "    std_prec = float(np.std(fold_prec_scores))\n",
    "    mean_rec = float(np.mean(fold_rec_scores))\n",
    "    std_rec = float(np.std(fold_rec_scores))\n",
    "\n",
    "    print(f\"Configuration {cfg} => \"\n",
    "          f\"F1: {mean_f1:.4f}  {std_f1:.4f} | \"\n",
    "          f\"Acc: {mean_acc:.4f}  {std_acc:.4f} | \"\n",
    "          f\"Prec: {mean_prec:.4f}  {std_prec:.4f} | \"\n",
    "          f\"Rec: {mean_rec:.4f}  {std_rec:.4f}\")\n",
    "\n",
    "    # Update best configuration\n",
    "    if mean_f1 > best_mean_f1:\n",
    "        best_mean_f1, best_cfg = mean_f1, cfg\n",
    "        best_std_f1 = std_f1\n",
    "        best_mean_acc, best_std_acc = mean_acc, std_acc\n",
    "        best_mean_prec, best_std_prec = mean_prec, std_prec\n",
    "        best_mean_rec, best_std_rec = mean_rec, std_rec\n",
    "\n",
    "# Display best results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> BEST CONFIGURATION FOUND:\")\n",
    "print(best_cfg)\n",
    "print(\"\\nCross-Validation Performance (macro metrics):\")\n",
    "print(f\"  F1 Score  : {best_mean_f1:.4f}  {best_std_f1:.4f}\")\n",
    "print(f\"  Accuracy  : {best_mean_acc:.4f}  {best_std_acc:.4f}\")\n",
    "print(f\"  Precision : {best_mean_prec:.4f}  {best_std_prec:.4f}\")\n",
    "print(f\"  Recall    : {best_mean_rec:.4f}  {best_std_rec:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save best configuration\n",
    "if MODEL_TYPE != \"Ensemble\":\n",
    "    save_best_config(MODEL_TYPE, best_cfg)\n",
    "\n",
    "# Save best configuration in models folder\n",
    "os.makedirs(os.path.join(MODELS_DIR, timestamp), exist_ok=True)\n",
    "with open(os.path.join(MODELS_DIR, timestamp, \"best_cfg.json\"), \"w\") as f:\n",
    "    json.dump(best_cfg, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying final preprocessing on full dataset...\n",
      "Final feature dimension: 40\n",
      "Number of classes: 3\n",
      "Total sequences loaded: 661\n",
      "Total labels loaded: 661\n",
      "Total sequences loaded: 1324\n",
      "\n",
      "Training final model with best configuration...\n",
      "Loaded best config for CNN1D -> key 'cnn'\n",
      "Loaded best config for GRU -> key 'gru'\n",
      "Loaded best config for LSTM -> key 'lstm'\n",
      "Loaded best config for Transformer -> key 'transformer'\n",
      "Loaded best config for MLP -> key 'mlp'\n",
      "Starting final training...\n",
      "[FINAL TRAINING] Epoch 5/75 - Train Loss: 0.3489\n",
      "[FINAL TRAINING] Epoch 10/75 - Train Loss: 0.1740\n",
      "[FINAL TRAINING] Epoch 15/75 - Train Loss: 0.0971\n",
      "[FINAL TRAINING] Epoch 20/75 - Train Loss: 0.0746\n",
      "[FINAL TRAINING] Epoch 25/75 - Train Loss: 0.0443\n",
      "[FINAL TRAINING] Epoch 30/75 - Train Loss: 0.0249\n",
      "[FINAL TRAINING] Epoch 35/75 - Train Loss: 0.0786\n",
      "[FINAL TRAINING] Epoch 40/75 - Train Loss: 0.0360\n",
      "[FINAL TRAINING] Epoch 45/75 - Train Loss: 0.0389\n",
      "[FINAL TRAINING] Epoch 50/75 - Train Loss: 0.0343\n",
      "[FINAL TRAINING] Epoch 55/75 - Train Loss: 0.0127\n",
      "[FINAL TRAINING] Epoch 60/75 - Train Loss: 0.0117\n",
      "[FINAL TRAINING] Epoch 65/75 - Train Loss: 0.0245\n",
      "[FINAL TRAINING] Epoch 70/75 - Train Loss: 0.0279\n",
      "[FINAL TRAINING] Epoch 75/75 - Train Loss: 0.0256\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss plot saved to: models\\20251117-181923\\final_training_loss.png\n",
      "Hyperparameters saved to: models\\20251117-181923\\hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "# ===== Final Preprocessing on Full Dataset =====\n",
    "print(\"Applying final preprocessing on full dataset...\")\n",
    "\n",
    "# One-hot encoding on full dataset\n",
    "X_train_full_enc = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "X_test_full_enc = pd.get_dummies(X_test, columns=categorical_cols)\n",
    "X_test_full_enc = X_test_full_enc.reindex(columns=X_train_full_enc.columns, fill_value=0)\n",
    "\n",
    "# Remove constant column\n",
    "for c in ['joint_30']:\n",
    "    if c in X_train_full_enc.columns:\n",
    "        X_train_full_enc.drop(columns=[c], inplace=True)\n",
    "        X_test_full_enc.drop(columns=[c], inplace=True)\n",
    "\n",
    "# Apply preprocessing pipeline to full dataset\n",
    "X_train_full_pp, X_test_full_pp = apply_preprocessing(\n",
    "    X_train_full_enc, X_test_full_enc, gaussian_joints, PREPROCESSING_OPTS[\"gaussian\"]\n",
    ")\n",
    "X_train_full_pp, X_test_full_pp = apply_scaler(\n",
    "    X_train_full_pp, X_test_full_pp, gaussian_joints, SCALER_OPTS[\"gaussian\"]\n",
    ")\n",
    "\n",
    "X_train_full_pp, X_test_full_pp = apply_preprocessing(\n",
    "    X_train_full_pp, X_test_full_pp, exp_joints, PREPROCESSING_OPTS[\"exp\"]\n",
    ")\n",
    "X_train_full_pp, X_test_full_pp = apply_scaler(\n",
    "    X_train_full_pp, X_test_full_pp, exp_joints, SCALER_OPTS[\"exp\"]\n",
    ")\n",
    "\n",
    "X_train_full_pp, X_test_full_pp = apply_preprocessing(\n",
    "    X_train_full_pp, X_test_full_pp, pain_cols, PREPROCESSING_OPTS[\"pain\"]\n",
    ")\n",
    "X_train_full_pp, X_test_full_pp = apply_scaler(\n",
    "    X_train_full_pp, X_test_full_pp, pain_cols, SCALER_OPTS[\"pain\"]\n",
    ")\n",
    "\n",
    "# Define final feature columns\n",
    "onehot_cols_full = [c for c in X_train_full_pp.columns if any(k in c for k in ['n_legs_', 'n_hands_', 'n_eyes_'])]\n",
    "base_cols_full = [c for c in (pain_cols + gaussian_joints + exp_joints) if c in X_train_full_pp.columns]\n",
    "feature_cols_full = base_cols_full + onehot_cols_full\n",
    "input_dim_full = len(feature_cols_full)\n",
    "num_classes = len(label_mapping)\n",
    "\n",
    "print(f\"Final feature dimension: {input_dim_full}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Create final datasets and data loaders\n",
    "final_train_ds = PiratePainSeqDataset(X_train_full_pp, y_train, feature_cols=feature_cols_full)\n",
    "test_dataset = PiratePainSeqDataset(X_test_full_pp, feature_cols=feature_cols_full)\n",
    "\n",
    "final_train_loader = DataLoader(final_train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "# ===== Train Final Model with Best Configuration =====\n",
    "print(f\"\\nTraining final model with best configuration...\")\n",
    "model = build_model_by_type(best_cfg, input_dim=input_dim_full, num_classes_arg=num_classes)\n",
    "lr = best_cfg.get(\"lr\", LR if best_cfg[\"type\"] != \"Transformer\" else LR * 0.5)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Final training with logging\n",
    "print(\"Starting final training...\")\n",
    "final_logs = []\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss_epoch = train_one_epoch(model, final_train_loader, optimizer, criterion)\n",
    "    final_logs.append({\"epoch\": epoch, \"train_loss\": train_loss_epoch})\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"[FINAL TRAINING] Epoch {epoch}/{NUM_EPOCHS} - Train Loss: {train_loss_epoch:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "if len(final_logs) > 0:\n",
    "    logs_df = pd.DataFrame(final_logs)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(logs_df['epoch'], logs_df['train_loss'], marker='o', linewidth=2, markersize=4)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Final Model Training Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = os.path.join(MODELS_DIR, timestamp, \"final_training_loss.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Training loss plot saved to: {plot_path}\")\n",
    "\n",
    "# Save hyperparameters\n",
    "hyperparameters = {\n",
    "    \"MODEL_TYPE\": MODEL_TYPE,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "    \"LR\": LR,\n",
    "    \"VALID_SPLIT\": VALID_SPLIT,\n",
    "    \"EARLY_STOPPING_PATIENCE\": EARLY_STOPPING_PATIENCE,\n",
    "    \"PREPROCESSING_OPTS\": PREPROCESSING_OPTS,\n",
    "    \"SCALER_OPTS\": SCALER_OPTS,\n",
    "    \"epsilon\": epsilon,\n",
    "    \"best_configuration\": best_cfg,\n",
    "    \"cv_performance\": {\n",
    "        \"f1_score\": f\"{best_mean_f1:.4f}  {best_std_f1:.4f}\",\n",
    "        \"accuracy\": f\"{best_mean_acc:.4f}  {best_std_acc:.4f}\",\n",
    "        \"precision\": f\"{best_mean_prec:.4f}  {best_std_prec:.4f}\",\n",
    "        \"recall\": f\"{best_mean_rec:.4f}  {best_std_rec:.4f}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "hyperparams_path = os.path.join(MODELS_DIR, timestamp, \"hyperparameters.json\")\n",
    "with open(hyperparams_path, 'w') as f:\n",
    "    json.dump(hyperparameters, f, indent=4)\n",
    "print(f\"Hyperparameters saved to: {hyperparams_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|| 21/21 [00:03<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " File saved at: prediction\\submission.csv\n",
      "label\n",
      "high_pain     150\n",
      "low_pain      153\n",
      "no_pain      1021\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Sample of submission file:\n",
      "  sample_index      label\n",
      "0          000    no_pain\n",
      "1          001    no_pain\n",
      "2          002    no_pain\n",
      "3          003    no_pain\n",
      "4          004    no_pain\n",
      "5          005  high_pain\n",
      "6          006    no_pain\n",
      "7          007    no_pain\n",
      "8          008    no_pain\n",
      "9          009    no_pain\n",
      "\n",
      " Model saved to: models\\20251117-181923\\final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# ===== Generate Predictions =====\n",
    "print(\"Generating predictions on test set...\")\n",
    "\n",
    "label_map = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        predictions.append(y_pred.argmax(1).cpu().numpy())\n",
    "\n",
    "# Process predictions\n",
    "predictions = np.concatenate(predictions)\n",
    "predicted_labels = [label_map[p] for p in predictions]\n",
    "\n",
    "# Get sample indices from test set\n",
    "sample_indices = X_test['sample_index'].drop_duplicates().reset_index(drop=True)\n",
    "sample_indices_str = sample_indices.apply(lambda x: f\"{x:03d}\")\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    \"sample_index\": sample_indices_str,\n",
    "    \"label\": predicted_labels\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_path = os.path.join(PRED_DIR, \"submission.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\" File saved at: {submission_path}\")\n",
    "print(submission['label'].value_counts().sort_index())\n",
    "\n",
    "# Display sample of submission\n",
    "print(\"\\n Sample of submission file:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Save model if desired\n",
    "model_save_path = os.path.join(MODELS_DIR, timestamp, \"final_model.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'best_config': best_cfg,\n",
    "    'feature_cols': feature_cols_full,\n",
    "    'label_mapping': label_mapping\n",
    "}, model_save_path)\n",
    "print(f\"\\n Model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive framework for pirate pain prediction using multiple deep learning architectures. Key features include:\n",
    "\n",
    "- Data preprocessing and feature engineering\n",
    "- Multiple model architectures (LSTM, GRU, Transformer, CNN1D, MLP, GNN, Ensemble)\n",
    "- Cross-validation and hyperparameter tuning\n",
    "- Attention mechanisms and advanced pooling techniques\n",
    "- Comprehensive evaluation metrics\n",
    "\n",
    "The implementation is modular and allows easy switching between different model types through configuration changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (GPU)",
   "language": "python",
   "name": "gpu-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
